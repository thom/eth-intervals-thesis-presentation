%==============================================================================
% presentation.tex
%==============================================================================


%==============================================================================
% Configuration
%==============================================================================

% Internationalisation
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% \usepackage[ngerman]{babel}

% Miscellaneous packages
\usepackage{url}
\usepackage{color,listings,paralist}
\usepackage{enumerate}
\usepackage{tabularx}
\usepackage{alltt}
\usepackage{wasysym}

% Use default Acrobat reader fonts
\usepackage{mathpazo}

% Use CM fonts (increases document size)
\usepackage{ae}

% Use images
\usepackage{graphicx}

% Configure beamer
\usetheme[secheader]{Ikhono}
\usefonttheme[onlylarge]{structurebold}
\setbeamertemplate{navigation symbols}{}

% Variables
\providecommand{\Title}{An Advanced Scheduler for Intervals}
\providecommand{\Subtitle}{Master's Thesis}
\providecommand{\Author}{Thomas Weibel <weibelt@ethz.ch>}
\providecommand{\Institute}{Laboratory for Software Technology, \\
  Swiss Federal Institute of Technology Z\"urich}
\providecommand{\Date}{September 7, 2010}

% PDF settings
\hypersetup{
  pdftitle={\Title, \Subtitle},
  pdfauthor={\Author},
  pdfsubject={\Institute},
  pdfkeywords={Master's Thesis, Thomas Weibel,
    Intervals, Parallel Programming}
}

% Titlepage
\title{\Title}
\subtitle{\Subtitle}
\author{\Author}
\institute{\Institute}
\date{\Date}

% Listings
\lstdefinestyle{Default}{
  language=Java,
  tabsize=2,
  mathescape=true,
  inputencoding=utf8,
  showstringspaces=false,
  fontadjust=true,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\bfseries,
}
\lstset{style=Default}


%==============================================================================
% Document
%==============================================================================

\begin{document}


% Titlepage
\begin{frame}[plain]
  \titlepage
\end{frame}

\note{
  \begin{itemize}
  \item Hi and welcome to my talk.
  \item I'm going to present the work from my Master's thesis. The
    topic of my thesis was ``Advanced Scheduling for Intervals''.
  \end{itemize}
}


\section*{Introduction}

\begin{frame}{Executive Summary}
  \begin{itemize}
  \item Advanced work-stealing scheduler for intervals
    \begin{itemize}
    \item[$\rightarrow$] Locality-aware scheduling using locality
      hints provided by the programmer
    \end{itemize}
  \item Providing locality hints to intervals is optional
    \begin{itemize}
    \item[$\rightarrow$] Performance of locality-ignorant programs
      executed with the new scheduler implementation is comparable to
      the original scheduler
    \end{itemize}
  \item Locality hints improve runtime and cache hit and miss rates
    \begin{itemize}
    \item[$\rightarrow$] \emph{Best locality} placement achieves up to
      $1.15\times$ speedup over \emph{worst} or \emph{ignorant
        locality} placement
    \item[$\rightarrow$] Cache hits are increased by up to $1.5\times$
      and cache misses are reduced by up to $3.1\times$
    \end{itemize}
  \end{itemize}
\end{frame}

\note{ 
  \begin{itemize}
  \item In my thesis we implemented and analyzed an advanced scheduler
    for intervals which is designed for locality-aware scheduling
    using locality hints provided by the programmer.
  \item Providing locality hints to intervals is optional and the
    performance of locality-ignorant programs executed with the new
    scheduler implementation is comparable to that of the original
    scheduler.
  \item We studied the performance of our new scheduler implementation
    with benchmarks using data sharing intervals. Our experimental
    results show that \emph{best locality} placement of intervals
    achieves up to 15 percent speedup over \emph{worst} or
    \emph{ignorant locality} placement. Cache hits are increased by up
    to 50 percent and cache misses are reduced by up to 310 percent.
  \end{itemize}
}

\begin{frame}{Intervals}
  \begin{itemize}
  \item Intervals are a new, higher-level primitive for multi-threaded
    programming allowing programmers to directly construct the program
    schedule. They are under active development at ETH Zürich as part
    of the PhD research of Nicholas D. Matsakis.
  \item The intervals implementation in Java uses a work-stealing
    scheduler where a worker running out of work tries to steal work
    from others. The scope of this thesis is to improve the
    performance of the intervals scheduler.
  \item Traditional primitives for synchronizing multi-threaded
    programs, such as semaphores and barriers, are low-level and
    dangerous to use. They are prone to errors, especially deadlocks
    and race conditions, and require careful attention to
    implementation details to achieve good performance.
  \item Intervals are a higher-level alternative that make parallel
    programming more secure while maintaining the flexibility and
    efficiency of threads. When using intervals, programmers create
    lightweight tasks and order them using \emph{happens before}
    relations. Programmers need not specify when tasks should block or
    acquire a lock. Instead they define when a task should execute in
    relation to other tasks, and what locks it should hold during
    execution. It is the duty of the runtime system to make this
    schedule pass.
  \item The intervals API supports arbitrary \emph{happens before}
    relations making the model very flexible. Intervals can be used to
    emulate existing thread primitives, but they can also be used to
    create program schedules for which no standard primitives exist,
    for example peer-to-peer synchronization.
  \item Intervals can be extended to support both runtime and static
    checks for errors like data race protection and deadlocks. An
    error in one task prevents other, dependent tasks from executing.
  \end{itemize}
\end{frame}

\note{
  \begin{itemize}
  \item Intervals are a new, higher-level primitive for multi-threaded
    programming allowing programmers to directly construct the program
    schedule. They are under active development at ETH Zürich as part
    of the PhD research of Nicholas D. Matsakis.
  \item The intervals implementation in Java uses a work-stealing
    scheduler where a worker running out of work tries to steal work
    from others. The scope of this thesis is to improve the
    performance of the intervals scheduler.
  \item Traditional primitives for synchronizing multi-threaded
    programs, such as semaphores and barriers, are low-level and
    dangerous to use. They are prone to errors, especially deadlocks
    and race conditions, and require careful attention to
    implementation details to achieve good performance.
  \item Intervals are a higher-level alternative that make parallel
    programming more secure while maintaining the flexibility and
    efficiency of threads. When using intervals, programmers create
    lightweight tasks and order them using \emph{happens before}
    relations. Programmers need not specify when tasks should block or
    acquire a lock. Instead they define when a task should execute in
    relation to other tasks, and what locks it should hold during
    execution. It is the duty of the runtime system to make this
    schedule pass.
  \item The intervals API supports arbitrary \emph{happens before}
    relations making the model very flexible. Intervals can be used to
    emulate existing thread primitives, but they can also be used to
    create program schedules for which no standard primitives exist,
    for example peer-to-peer synchronization.
  \item Intervals can be extended to support both runtime and static
    checks for errors like data race protection and deadlocks. An
    error in one task prevents other, dependent tasks from executing.
  \end{itemize}
}

\begin{frame}{Work-Stealing Scheduler}
  TODO
\end{frame}

\note{
  The implementation of intervals for Java makes use of a
  work-stealing scheduler similar to those found in Cilk, Java 7,
  Intel Threading Building Blocks, or Microsoft Task Parallel Library
  but extended to support locks and happens before edges.

  A work-stealing scheduler employs a fixed number of threads called
  workers. Each worker has a local double-ended queue, or deque, to
  maintain its own pool of ready tasks from which it obtains
  work. When a worker finds that its pool is empty, it steals a task
  from the pool of a victim worker chosen at random.

  To obtain work, a worker takes the ready task from the tail of its
  deque and executes it. If the task terminates, the worker goes back
  to the tail of its deque to take another task upon which it can
  work. When assigning a new task to a worker, the worker puts the
  newly ready task onto the tail of its deque. Thus, as long as a
  worker's deque is not empty, the worker manipulates its deque in a
  LIFO (stack-like) manner.

  When a worker tries to obtain work by taking a task from the tail of
  its deque and it finds that it is empty, the worker becomes a
  thief. It picks a victim worker at random and attempts to obtain
  work by removing the task at the head of the victim's deque. If the
  victim's deque is empty, then the thief picks another victim worker
  and tries again until it finds a victim whose deque it not empty. At
  which point the thief continues to work on the stolen task as
  described above. Since steals take place at the head of the victim's
  deque, stealing operates in a FIFO manner.

  Accessing the run queues at different ends offers several advantages:

  \begin{itemize}
  \item It reduces contention by having owner and thieves working on
    opposite sides of the deque.
  \item Recursive divide-and-conquer algorithms generate ``large''
    tasks early. Thus, the older stolen task is likely to further
    provide more work to the stealing worker.
  \item Stealing a task also migrates its future workload, which helps
    to increase locality.
  \end{itemize}

  The assignment of tasks to workers for execution is done in a
  provably efficient manner.
}


\section{Locality-Aware Intervals Scheduling}

\begin{frame}{Outline}
  \tableofcontents[current]
\end{frame}

\note{
}

\begin{frame}{TODO}
  TODO
\end{frame}

\note{
  The current implementation of the intervals library uses a
  locality-ignorant work-stealing scheduler to schedule ready-to-run
  tasks. In this thesis we introduce LASSI, a locality-aware scheduler
  for intervals. The correct acronym would be LASI but we chose LASSI
  instead as we really enjoy drinking refreshing masala lassi \smiley

  % Scheduling

  In chip multiprocessor systems it may be more efficient to schedule
  a task on one processor than another. As modern CMPs feature a
  heterogeneous memory hierarchy where access times depend on which
  processor an interval is running, locality-aware intervals can lead
  to improved performance:

  \begin{itemize}
  \item By scheduling data sharing intervals on the same processor
    they perform prefetching of shared regions for one another.
  \item Scheduling non-communicating intervals with high memory
    footprints on different processors helps to reduce cache
    contention and potential cache capacity problems.
  \end{itemize}

  When using locality-ignorant work-stealing we cannot fully exploit
  the heterogeneous memory hierarchy of CMPs for our benefit. Thus, we
  implement and analyze LASSI, a locality-aware scheduler for
  intervals. LASSI is designed for locality-aware scheduling using
  locality hints provided by the programmer. Instead of employing
  work-stealing workers, it groups workers into \emph{Work-Stealing
    Places}.

  Each work-stealing place has a fixed number of workers and a local
  deque to maintain ready tasks. The workers of a place share its
  local deque from which they obtain work. When a worker finds that
  the pool of its place is empty, it tries to steal a task from the
  pool of a victim place chosen at random. Locality-aware intervals
  are added to their preferred place once they are ready for
  scheduling.

  Providing locality hints to intervals is optional and the
  performance of locality-ignorant programs executed with the new
  scheduler implementation is comparable to that of the original
  scheduler.

  We study the performance of LASSI with benchmarks using data sharing
  intervals. Our experimental results show that \emph{best locality}
  placement of intervals can achieve up to $1.15\times$ speedup over
  \emph{worst} or \emph{ignorant locality} placement. Cache hits can
  be increased by up to $1.5\times$ and cache misses can be reduced by
  up to $3.1\times$ for the benchmarks and platform studied in this
  thesis.
}


\section{Approach}

\begin{frame}{Outline}
  \tableofcontents[current]
\end{frame}

\note{
}

\begin{frame}{TODO}
  TODO
\end{frame}

\note{
}


\section{Implementation}

\begin{frame}{Outline}
  \tableofcontents[current]
\end{frame}

\note{
}

\begin{frame}{TODO}
  TODO
\end{frame}

\note{
}


\section{Performance Evaluation}

\begin{frame}{Outline}
  \tableofcontents[current]
\end{frame}

\note{
}

\begin{frame}{TODO}
  TODO
\end{frame}

\note{
}


\section{Related Work}

\begin{frame}{Outline}
  \tableofcontents[current]
\end{frame}

\note{
}

\begin{frame}{TODO}
  TODO
\end{frame}

\note{
}


\section{Conclusions and Future Work}

\begin{frame}{Outline}
  \tableofcontents[current]
\end{frame}

\note{
}

\begin{frame}{TODO}
  TODO
\end{frame}

\note{
}


\section*{Outro}

\begin{frame}{Summary}
  \begin{itemize}
  \item TODO
  \end{itemize}
\end{frame}

\note{
}

\begin{frame}
  \begin{center}
    \huge Questions?
  \end{center}
\end{frame}

\note{
}


\appendix

\section{Appendix}

\subsection{Work-Stealing Queue Implementations}

\begin{frame}{Introduction}
  \begin{itemize}
  \item The performance of work-stealing schedulers is in a large part
    determined by the efficiency of their work queue
    implementations. In the non-blocking work-stealing scheduler, the
    queues are implemented with non-blocking synchronization. That is,
    instead of using mutual exclusion, it uses atomic synchronization
    primitives such as Compare-and-Swap. The current work-stealing
    queue of intervals however uses mutual exclusion when trying to
    steal. Thus, as a separate effort, we design and explore
    alternative non-blocking queue implementations with the aim to
    improve work-stealing performance.
  \end{itemize}
\end{frame}

\note{
  \begin{itemize}
  \item The performance of work-stealing schedulers is in a large part
    determined by the efficiency of their work queue
    implementations. In the non-blocking work-stealing scheduler, the
    queues are implemented with non-blocking synchronization. That is,
    instead of using mutual exclusion, it uses atomic synchronization
    primitives such as Compare-and-Swap. The current work-stealing
    queue of intervals however uses mutual exclusion when trying to
    steal. Thus, as a separate effort, we design and explore
    alternative non-blocking queue implementations with the aim to
    improve work-stealing performance.
  \end{itemize}
}

\subsection{Bibliography}

\begin{frame}
  TODO

  \begin{thebibliography}{10}
    % Articles
    \beamertemplatearticlebibitems

  \bibitem{zpl}
    B. Chamberlain et al., {\em ZPL: A Machine Independent Language
      for Parallel Computers},
    \url{http://www.cs.washington.edu/research/zpl/papers/data/Chamberlain00ZPL.pdf}
    
  \bibitem{zpl-design}
    B. Chamberlain, {\em The Design and Implementation of a
      Region-Based Parallel Programming Language},
    \url{http://www.cs.washington.edu/research/zpl/papers/data/Chamberlain01Design.pdf}

  \bibitem{shared-memory}
    L. Snyder, {\em Type Architecture, Shared Memory and the Corollary
      of Modest Potential}, Ann. Review of Computer Science,
    pp. I:289-318, 1986

  \bibitem{nas-mg-benchmark}
    B. Chamberlain et al., {\em A Comparative Study of the NAS MG
      Benchmark across Parallel Languages and Architectures},
    \url{http://www.cs.washington.edu/research/zpl/papers/data/Chamberlain00.pdf}
  \end{thebibliography}
\end{frame}

\note{
  Those are a few selected references I used in my work.
}

\end{document}
